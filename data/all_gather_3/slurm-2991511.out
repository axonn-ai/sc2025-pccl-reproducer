srun -N 2 -n 16 -c7 --gpus-per-task=1 --gpu-bind=closest python -u benchmark_all_gather.py
PE 0: MPICH CH4 OFI detected 4 NICs/node on host frontier09409
PE 0: MPICH CH4 OFI limiting NIC usage by setting of MPICH_OFI_NUM_NICS=[4]
PE 0: MPICH CH4 OFI netmod using cxi provider (domain_name=cxi2, src_addr=0x29433)
PE 0: Selected traffic class: [TC_BEST_EFFORT, 512]
PE 0: MPICH CH4 OFI CXI counters initialized
PE 0: MPICH CH4 OFI global connections for 16 ranks took 0.00211553 seconds.
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09409.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
output size = 1 MB
Method = nccl
All-gather bus bw for 16 GPUs is 1.740 GBPS for message output size 1.049 MB
time = 0.565 ms
Method = mpi
All-gather bus bw for 16 GPUs is 3.414 GBPS for message output size 1.049 MB
time = 0.288 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 3.548 GBPS for message output size 1.049 MB
time = 0.277 ms
===============================
output size = 2 MB
Method = nccl
All-gather bus bw for 16 GPUs is 4.158 GBPS for message output size 2.097 MB
time = 0.473 ms
Method = mpi
All-gather bus bw for 16 GPUs is 6.500 GBPS for message output size 2.097 MB
time = 0.302 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 6.773 GBPS for message output size 2.097 MB
time = 0.290 ms
===============================
output size = 4 MB
Method = nccl
All-gather bus bw for 16 GPUs is 6.894 GBPS for message output size 4.194 MB
time = 0.570 ms
Method = mpi
All-gather bus bw for 16 GPUs is 9.650 GBPS for message output size 4.194 MB
time = 0.407 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 12.965 GBPS for message output size 4.194 MB
time = 0.303 ms
===============================
output size = 8 MB
Method = nccl
All-gather bus bw for 16 GPUs is 13.794 GBPS for message output size 8.389 MB
time = 0.570 ms
Method = mpi
All-gather bus bw for 16 GPUs is 12.088 GBPS for message output size 8.389 MB
time = 0.651 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 24.968 GBPS for message output size 8.389 MB
time = 0.315 ms
===============================
output size = 16 MB
Method = nccl
All-gather bus bw for 16 GPUs is 26.890 GBPS for message output size 16.777 MB
time = 0.585 ms
Method = mpi
All-gather bus bw for 16 GPUs is 14.018 GBPS for message output size 16.777 MB
time = 1.122 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 36.424 GBPS for message output size 16.777 MB
time = 0.432 ms
===============================
output size = 32 MB
Method = nccl
All-gather bus bw for 16 GPUs is 48.068 GBPS for message output size 33.554 MB
time = 0.654 ms
Method = mpi
All-gather bus bw for 16 GPUs is 15.217 GBPS for message output size 33.554 MB
time = 2.067 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 47.309 GBPS for message output size 33.554 MB
time = 0.665 ms
===============================
output size = 64 MB
Method = nccl
All-gather bus bw for 16 GPUs is 66.068 GBPS for message output size 67.109 MB
time = 0.952 ms
Method = mpi
All-gather bus bw for 16 GPUs is 21.591 GBPS for message output size 67.109 MB
time = 2.914 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 56.200 GBPS for message output size 67.109 MB
time = 1.119 ms
===============================
output size = 128 MB
Method = nccl
All-gather bus bw for 16 GPUs is 69.313 GBPS for message output size 134.218 MB
time = 1.815 ms
Method = mpi
All-gather bus bw for 16 GPUs is 22.675 GBPS for message output size 134.218 MB
time = 5.549 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 60.882 GBPS for message output size 134.218 MB
time = 2.067 ms
===============================
output size = 256 MB
Method = nccl
All-gather bus bw for 16 GPUs is 70.865 GBPS for message output size 268.435 MB
time = 3.551 ms
Method = mpi
All-gather bus bw for 16 GPUs is 23.153 GBPS for message output size 268.435 MB
time = 10.870 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 63.337 GBPS for message output size 268.435 MB
time = 3.973 ms
===============================
output size = 512 MB
Method = nccl
All-gather bus bw for 16 GPUs is 70.965 GBPS for message output size 536.871 MB
time = 7.092 ms
Method = mpi
All-gather bus bw for 16 GPUs is 23.426 GBPS for message output size 536.871 MB
time = 21.485 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 62.478 GBPS for message output size 536.871 MB
time = 8.056 ms
===============================
output size = 1024 MB
Method = nccl
All-gather bus bw for 16 GPUs is 71.671 GBPS for message output size 1073.742 MB
time = 14.045 ms
Method = mpi
All-gather bus bw for 16 GPUs is 23.534 GBPS for message output size 1073.742 MB
time = 42.773 ms
Method = hybrid
All-gather bus bw for 16 GPUs is 61.511 GBPS for message output size 1073.742 MB
time = 16.365 ms
===============================
{'mpi': [3.41391176982254, 6.500228709321655, 9.65015919581804, 12.087977976431768, 14.018034661420232, 15.2169075300337, 21.590620752111153, 22.67465297280134, 23.152646073550425, 23.42639242354377, 23.534475190386836], 'rccl': [1.7403179532435402, 4.157683536078186, 6.8944803435302315, 13.793986340660457, 26.88995144577204, 48.06819700168046, 66.06801957572112, 69.31315928805884, 70.86523784487818, 70.96546915261193, 71.67056546189117], 'hybrid': [3.5477627699614827, 6.7732519385248615, 12.964798981032994, 24.968077113096328, 36.4238125079979, 47.30943107626634, 56.199556206722555, 60.88223574477817, 63.3365453903514, 62.478492031730156, 61.51103032793891]}

MPICH Slingshot Network Summary: 0 network timeouts

